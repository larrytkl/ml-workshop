{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes for a \"Getting started\" workshop\n",
    "\n",
    "We're going to run through a series of steps and challenges. If you get stuck at any point please feel free to ask one of our volunteers for help!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Anaconda\n",
    "\n",
    "### On a JPMC machine\n",
    "\n",
    "1. Go to https://fastxchange.jpmchase.net/software/#home\n",
    "2. Search for \"Anaconda\"\n",
    "3. Install \"Anaconda for Python 3.x\"\n",
    "\n",
    "### On your own machine\n",
    "\n",
    "Go to https://www.continuum.io/downloads/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Jupyter Notebook\n",
    "\n",
    "Jupyter is a tool for interacting with code and data in a variety of languages. Today (obviously) we're using it with Python 3, but you can find out more about what it can do at http://jupyter.org/\n",
    "\n",
    "### On a JPMC machine\n",
    "\n",
    "1. Start > All Programs > Anaconda 3 > Anaconda Prompt\n",
    "2. Type `jupyter notebook`\n",
    "\n",
    "### On your own machine\n",
    "\n",
    "Just from Start > All Programs > Anaconda > Jupyter (or similar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get the workshop notebook\n",
    "\n",
    "1. Download https://joehalliwell.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Jupyter basics\n",
    "\n",
    "When you started Jupyter a new browser tab should have opened. Click the \"New\" button and then select \"Python\" to start a new Python Notebook.\n",
    "\n",
    "### Challenges\n",
    "\n",
    "1. Go to the \"Help\" menu above and run through the \"User Interface Tour\"\n",
    "2. Click into the \"In\" box below and hit `control + enter` to execute it. What happens?\n",
    "3. Click the \"+\" button to create a new code block. Type in `1337 + 1337` and hit `control + enter` to evaluate.\n",
    "4. Click the scissors button to remove it\n",
    "5. Pop-up documentation by click on the word format and pressing `shift + tab`. You can use the controls in the top-right of the pop-up to see more info.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getuser\n",
    "print(\"{0} RULEZ!!!\".format(getuser()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Python basics\n",
    "\n",
    "Practice a bit of Python. Skip this if you're totally on top of the Python thing.\n",
    "\n",
    "### Challenges\n",
    "\n",
    "1. Print the result of *multiplying* `1337` by `1337`\n",
    "2. Create a list called `adjectives` containing *five* adjectives\n",
    "3. Print the length of `adjectives`\n",
    "3. Import the `choice` function from the `random` standard library; use it to print a random adjective\n",
    "4. Do the same with `nouns` a list of nouns\n",
    "5. Define a function `codename` to return a random combination of adjective and noun\n",
    "6. (**Tricky!**) Generate five *distinct* codenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# SPOILER ALERT! THIS SECTION IS TO BE REMOVED BEFORE DISTRIBUTION #\n",
    "####################################################################\n",
    "\n",
    "print(1337 * 1337)\n",
    "\n",
    "adjectives = [\"guilty\", \"horrid\", \"intrepid\", \"jilted\", \"kingly\"]\n",
    "\n",
    "print(len(adjectives))\n",
    "\n",
    "from random import choice\n",
    "print(choice(adjectives))\n",
    "\n",
    "nouns = [\"apple\", \"bacon\", \"carbon\", \"dinghy\", \"echo\"]\n",
    "print(choice(nouns))\n",
    "\n",
    "def codename():\n",
    "    return choice(adjectives) + \" \" + choice(nouns)\n",
    "    \n",
    "print(codename())\n",
    "\n",
    "codenames = set()\n",
    "while len(codenames) < 5:\n",
    "    codenames.add(codename())\n",
    "print(codenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pandas\n",
    "\n",
    "Pandas is a widely-used library for working with tables of data called \"dataframes\". You can find out more at http://pandas.pydata.org/\n",
    "\n",
    "### Challenges\n",
    "\n",
    "1. Run the snippet below to read in the \"Titanic\" dataset from the interwebs. Do you understand what each line is doing?\n",
    "2. Run `titanic.head()` to look at the first few rows of the dataframe\n",
    "3. Experiment with the `sample()`, `info()` and `describe()` methods. Remember that you can use `shift + tab` to access documentation!\n",
    "4. Why are the counts in the `info()` output different for different fields?\n",
    "4. The average age in the dataset can be found via `titanic['Age'].mean()`, but what is the sum of eveyone's ages?\n",
    "4. You can filter the dataset to just women via `titanic[titanic['Sex'] == 'female']`. What's the average age of women in the dataset?\n",
    "5. (**Tricky!**) What's the average age of female survivors?\n",
    "5. What is `titanic.groupby(['Sex', 'Survived']).describe()` showing you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pd.set_option('max_rows', 50)\n",
    "os.environ['HTTPS_PROXY'] = 'proxy.jpmchase.net:8443' # Comment this out if you're running it on your own machine\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/joehalliwell/ml-workshop/master/train.csv\"\n",
    "titanic = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# SPOILER ALERT! THIS SECTION IS TO BE REMOVED BEFORE DISTRIBUTION #\n",
    "####################################################################\n",
    "\n",
    "# Look at the first few entries\n",
    "titanic.sample(n=3)\n",
    "\n",
    "# The 'all' is required to include stats for non-numeric columns\n",
    "titanic.describe(include='all')\n",
    "\n",
    "# Sum of ages\n",
    "titanic['Age'].sum()\n",
    "\n",
    "# Annoyingly the brackets are essential\n",
    "titanic[(titanic['Sex'] == 'female') & (titanic['Survived'] == 1)]['Age'].mean()\n",
    "\n",
    "titanic.groupby(['Sex', 'Survived']).describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Matplotlib and Seaborn\n",
    "\n",
    "There are a lot of different Python libraries for visualising data. **Matplotlib** is one of the most powerful and widely used. In fact, as we'll see it's integrated with pandas! We're just going to be doing some basic charting, but you can see more of its capabilities at https://matplotlib.org/gallery.html.\n",
    "\n",
    "**Seaborn** gives matplotlib a nicer default style and provides some utility functions. You can read more about using it with pandas here: http://seaborn.pydata.org/tutorial/categorical.html\n",
    "\n",
    "### Challenges\n",
    "\n",
    "1. Run the snippets below to do some basic charting\n",
    "2. Take a look at the pandas visualisation guide https://pandas.pydata.org/pandas-docs/stable/visualization.html\n",
    "3. IDEAS PLEASE!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Pandas has built in methods for simple visualisations\n",
    "titanic[\"Sex\"].value_counts().plot(kind=\"bar\", title=\"Sex of passengers\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn offers concise ways to construct complex charts\n",
    "sns.barplot(x=\"Embarked\", y=\"Survived\", hue=\"Sex\", data=titanic)\n",
    "sns.pairplot(x_vars=[\"Age\"], y_vars=[\"Fare\"], data=titanic, hue=\"Embarked\", size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(titanic, col='Survived', row='Pclass', size=2.2, aspect=1)\n",
    "grid.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# You can also use matplotlib directly\n",
    "plt.hist(titanic['Fare'], label=\"Fare\")\n",
    "\n",
    "X = np.linspace(0, 600)\n",
    "for d in np.linspace(100, 600, 10):\n",
    "    plt.plot(X, d + 50 * np.sin(X / 50), linestyle='dotted', linewidth=10)\n",
    "    \n",
    "plt.title(\"Histogram of fares plus squiggles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Scikit Learn\n",
    "\n",
    "Scikit Learn (http://scikit-learn.org) is a brilliant library that contains a bunch of textbook machine learning algorithms, plus machinery for running and evaluating experiments. We're going to use it to build a simple model called a decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scikit learn\n",
    "from sklearn import tree, metrics, preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is to tidy up our data and convert it numerical form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = titanic.copy()\n",
    "\n",
    "# First we're going to deal with some missing data\n",
    "# See https://pandas.pydata.org/pandas-docs/stable/missing_data.html \n",
    "\n",
    "# Here's the problem...\n",
    "problems = train.isnull().any(axis=1)\n",
    "print(train[problems].head())\n",
    "print(\"Problem rows: {0}\".format(train.isnull().any(axis=1).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_data(df):\n",
    "    # Replace missing ports of embarkation with 'U'\n",
    "    df['Embarked'] = df['Embarked'].fillna('U') # For unknown\n",
    "\n",
    "    # Replace missing ages with the median age\n",
    "    medianAge = df['Age'].dropna().median()\n",
    "    df['Age'] = df['Age'].fillna(medianAge)\n",
    "\n",
    "    # Replace missing cabins with 'U' and strip back to deck letter\n",
    "    df['Cabin'] = df['Cabin'].fillna('U')\n",
    "    df['Cabin'] = df['Cabin'].map(lambda cabin: cabin[0])\n",
    "\n",
    "    medianFare = df['Fare'].dropna().median()\n",
    "    df['Fare'] = df['Fare'].fillna(medianFare)\n",
    "    \n",
    "# Check that it's fixed\n",
    "fill_missing_data(train)\n",
    "print(train[problems].head())\n",
    "print(\"Problem rows: {0}\".format(train.isnull().any(axis=1).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to convert the \"categorical\" or \"nominal\" data into numbers. For the decision tree classifier we are going to train it's okay to just replace each category with a code number. We can do this automatically with Scikit Learn's LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = {col: preprocessing.LabelEncoder() for col in ('Cabin', 'Embarked', 'Sex')}\n",
    "\n",
    "def encode(df):\n",
    "    for col, encoder in encoders.items():\n",
    "         df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "encode(train)\n",
    "\n",
    "# Show the trained encoders\n",
    "for col, enc in encoders.items():\n",
    "    print(col, {c:enc.transform([c])[0] for c in enc.classes_})\n",
    "\n",
    "train.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = \"Pclass Sex Age Fare Cabin Embarked\".split()\n",
    "\n",
    "def split_labels(df):\n",
    "    data = df[cols]\n",
    "    labels = df[\"Survived\"]\n",
    "    return data, labels\n",
    "\n",
    "X, Y = split_labels(train)\n",
    "model = tree.DecisionTreeClassifier(max_depth=3)\n",
    "model.fit(X, Y)\n",
    "\n",
    "print(\"Accuracy on training data:\", model.score(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz # conda install python-graphviz\n",
    "\n",
    "dot = tree.export_graphviz(model, out_file=None, \n",
    "                         feature_names=trainX.columns,  \n",
    "                         class_names=['Died', 'Survived'],  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "graphviz.Source(dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we increase the max_depth of the decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(max_depth=10)\n",
    "model.fit(X, Y)\n",
    "print(\"Accuracy on training data:\", model.score(X, Y))\n",
    "print(metrics.classification_report(model.predict(X), Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try against some \"held out\" test data\n",
    "holdout = pd.read_csv('https://raw.githubusercontent.com/joehalliwell/ml-workshop/master/test.csv')\n",
    "\n",
    "test = holdout[cols].copy()\n",
    "\n",
    "fill_missing_data(test)\n",
    "encode(test)\n",
    "problems = test.isnull().any(axis=1)\n",
    "test[problems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Over to you!\n",
    "\n",
    "- Would a one-hot encoding be better? http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "- What's the best tree depth for controlling over-fitting?\n",
    "- Can you use SciKit's built in cross-validation/model selection to figure that out?\n",
    "- Try visualising the decision surface: http://scikit-learn.org/stable/auto_examples/tree/plot_iris.html#sphx-glr-auto-examples-tree-plot-iris-py \n",
    "\n",
    "\n",
    "## 10. References\n",
    "\n",
    "- Intro to pandas: http://synesthesiam.com/posts/an-introduction-to-pandas.html\n",
    "- Cheatsheets: https://startupsventurecapital.com/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5 \n",
    "- Titanic tutorials: https://www.kaggle.com/c/titanic#tutorials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Y = np.random.choice([0,1], size=10000)\n",
    "X = np.random.normal(Y * 2)\n",
    "\n",
    "df = pd.DataFrame(np.stack((X,Y)).transpose(), columns=\"x label\".split())\n",
    "\n",
    "plt.hist(df[df['label'] == 1]['x'], color='r', alpha=0.5)\n",
    "plt.hist(df[df['label'] == 0]['x'], color='g', alpha=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
